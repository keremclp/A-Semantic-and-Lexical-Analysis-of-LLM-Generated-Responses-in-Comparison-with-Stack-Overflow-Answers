import pandas as pd
import re

# ==========================================
# CLEAN AND PREPARE DATASET
# ==========================================

def clean_text(text):
    """Remove excessive whitespace and HTML entities"""
    if pd.isna(text):
        return ""
    
    text = str(text)
    # Decode HTML entities
    text = text.replace('&quot;', '"').replace('&amp;', '&')
    text = text.replace('&lt;', '<').replace('&gt;', '>')
    text = text.replace('&#39;', "'")
    
    # Remove excessive whitespace
    text = ' '.join(text.split())
    
    return text.strip()

print("ðŸ“‚ Veri seti okunuyor...")

try:
    # CRITICAL: Use proper CSV reading with quote handling
    df = pd.read_csv(
        'stackoverflow_with_gpt_answers.csv',
        encoding='utf-8-sig',
        quotechar='"',
        escapechar='\\',
        on_bad_lines='warn'  # Python 3.9+, shows warnings for bad lines
    )
    
    print(f"âœ… {len(df)} satÄ±r yÃ¼klendi")
    
except Exception as e:
    print(f"âŒ Hata: {e}")
    print("\nAlternatif okuma yÃ¶ntemi deneniyor...")
    
    # Alternative: Use engine='python' for more robust parsing
    df = pd.read_csv(
        'stackoverflow_with_gpt_answers.csv',
        encoding='utf-8-sig',
        engine='python',
        quotechar='"',
        escapechar='\\'
    )
    print(f"âœ… {len(df)} satÄ±r yÃ¼klendi (alternatif yÃ¶ntem)")

# ==========================================
# DATA CLEANING
# ==========================================

print("\nðŸ§¹ Veri temizleniyor...")

# 1. Remove rows with missing critical data
initial_count = len(df)
df = df.dropna(subset=['question_title', 'question_body', 'human_answer', 'gpt_answer'])
print(f"   - Eksik veri olan {initial_count - len(df)} satÄ±r kaldÄ±rÄ±ldÄ±")

# 2. Remove ERROR responses
error_count = df['gpt_answer'].str.contains('ERROR', case=False, na=False).sum()
if error_count > 0:
    df = df[~df['gpt_answer'].str.contains('ERROR', case=False, na=False)]
    print(f"   - ERROR iÃ§eren {error_count} satÄ±r kaldÄ±rÄ±ldÄ±")

# 3. Clean text fields
print("   - Metinler temizleniyor...")
df['question_title'] = df['question_title'].apply(clean_text)
df['question_body'] = df['question_body'].apply(clean_text)
df['human_answer'] = df['human_answer'].apply(clean_text)
df['gpt_answer'] = df['gpt_answer'].apply(clean_text)

# 4. Remove duplicates
dup_count = df.duplicated(subset=['question_id']).sum()
if dup_count > 0:
    df = df.drop_duplicates(subset=['question_id'], keep='first')
    print(f"   - {dup_count} duplike satÄ±r kaldÄ±rÄ±ldÄ±")

# 5. Remove empty or too short answers
min_length = 50  # Minimum character count for valid answers
df = df[
    (df['human_answer'].str.len() >= min_length) & 
    (df['gpt_answer'].str.len() >= min_length)
]
print(f"   - Ã‡ok kÄ±sa cevaplar kaldÄ±rÄ±ldÄ± (min: {min_length} karakter)")

# 6. Reset index
df = df.reset_index(drop=True)

# ==========================================
# SAVE CLEANED DATA
# ==========================================

output_file = 'stackoverflow_cleaned.csv'
df.to_csv(output_file, index=False, encoding='utf-8-sig')

print(f"\nâœ… TemizlenmiÅŸ veri seti kaydedildi: {output_file}")
print(f"ðŸ“Š Toplam temiz satÄ±r: {len(df)}")

# ==========================================
# DISPLAY STATISTICS
# ==========================================

print("\n" + "="*60)
print("VERÄ° SETÄ° Ä°STATÄ°STÄ°KLERÄ°")
print("="*60)

print(f"Toplam soru sayÄ±sÄ±: {len(df)}")
print(f"\nOrtalama karakter uzunluklarÄ±:")
print(f"  - Soru baÅŸlÄ±ÄŸÄ±: {df['question_title'].str.len().mean():.0f}")
print(f"  - Soru iÃ§eriÄŸi: {df['question_body'].str.len().mean():.0f}")
print(f"  - Ä°nsan cevabÄ±: {df['human_answer'].str.len().mean():.0f}")
print(f"  - GPT cevabÄ±: {df['gpt_answer'].str.len().mean():.0f}")

print(f"\nÄ°lk 5 soru:")
for idx, row in df.head(5).iterrows():
    print(f"  {idx+1}. {row['question_title'][:60]}...")

print("\n" + "="*60)